
1. Scalability & High Availability
    - Vertical Scalability
    - Horizontal Scalability

    for EC2
        Vertical Scaling : Increase instance size (= scale up / down)
            From : t2.nano - 0.5G of RAM, 1 vCPU
            To   : u-12tbl.metal - 12.3 TB of RAM, 448 vCPUs
        Horizontal Scaling : Increase number of instances (= scale out /in)
            Auto Scaling Group 
            Load Balancer 
        High Availability : Run instances for the same application across multi AZ 
            Auto Scaling Group multi AZ 
            Load Balancer multi AZ 


2. ELB (Elastic Load Balancer)
    What is Load balancing ?
        Load Balances are servers that forward traffic to multiple server (e.g., EC2 instances) downstream
    Why use a load balancer ?
        Spread load across multiple downstream instances 
        Expose a single point of access (DNS) to your application 
        Seamlessly handle failures of downstream instances 
        Do regular health checks to your instances 
        Provide SSL termination (HTTPS) for your websites
        Enforce stickiness with cookies
        High availability across zones 
        Separate public traffic from private traffic 

    Why use an Elastic Load Balancer ?
        An Elastic Load Balancer is a managed load balancer 
            AWS guarantees that it will be working 
            AWS takes care of upgrades, maintenance, high availability
            AWS provides only a few configuration knobs 
        It costs less to setup your own load balancer but it will be a lot more effort on your end 
        It is integrated with many AWS offerings / services 
            EC2, EC2 Auto Scaling Groups, Amazon ECS 
            AWS Certificate Manager (ACM), Cloud Watch 
            Route 53, AWS WAF, AWS Global Accelerator
    Health Checks 
        Health Checks are crucial for Load Balancers 
        They enable the load balancer to know if instances it forwards traffic to are available to reply to requests 
        The health check is done on a port and a route (/health is common)
        If the response is not 200 (OK), then the instance is unhealthy
    
    Types of load balancer on AWS 
        AWS has 4 kinds of managed Load Balancers 
        Classic Load Balancer (v1 - old generation) - 2009 - CLB 
            - HTTP, HTTPS, TCP, SSL(secure TCP)
        Application Load Balancer (v2 - new generation) -  2016 - ALB 
            - HTTP, HTTPS, WebSocket
        Network Load Balancer (v2 - new generation) - 2017 - NLB 
            - TCP, TLS(secure TCP), UDP 
        Gateway Load Balancer - 2020 - GWLB 
            - Operates at layer 3 (Network layer) - IP Protocol 
        Overall, it is recommended to use the newer generation load balancers as they provide more features 
        Some load balancers can be setup as internal (private) or external (public) ELBs 

    Load Balancer Security Groups 
        Users <-> Load Balancer <-> EC2
            Users <-> Load Balancer : HTTPS / HTTP From anywhere 
            Load Balancer <-> EC2   : Allow traffic only from Load Balancer (HTTP Restricted to Load Balancer)
        즉, Users가 Load Balancer에 접근할 때는 HTTP 80, HTTPS 443 으로 0.0.0.0/0으로 All Alow지만 ..
        실제로 EC2 Instance의 Security Group을 Load Balancer에 연결하면 EC2 Instance에 적용된 트래픽만을 허용하게 되어 강화된 보안 메커니즘이 된다.

    CLB f/o로 인한 시험 미출제 및 콘솔 사용 불가로 pass 


3. ALB (Application Load Balancer) v2 
    Application load balancers is Layer 7 (HTTP)
    Load balancing to multiple HTTP applications across machines (target groups)
    Load balancing to multiple applications on the same machine (ex: containers)
    Support for HTTP/2 and WebSocket 
    Support redirect (from HTTP to HTTPS for example)

    Routing tables to different target groups :
        Routing based on path in URL (example.com/users & example.com/posts)
        Routing based on hostname in URL (one.example.com & other.example.com)
        Routing based on Query String, Headers (example.com/users?id=123&order=false)
    ALB are a great fit for micro services & container-based application (example: Docker & Amazon ECS)
    Has a port mapping feature to redirect to a dynamic port in ECS 
    In comparsion, we'd need multiple Classic Load Balancer per application 

    Target Groups 
        EC2 instances (can be managed by an Auto Scaling Group) - HTTP 
        ECS tasks (managed by ECS itself) - HTTP 
        Lambda functions - HTTP request is translated into a JSON event 
        IP Addresses - must be private IPs 
        ALB can route to multiple target groups 
        Health Checks are at the target group level 

    Good to know
        Fixed hostname (XXX.region.elb.amazonaws.com)
        The application servers don't see the IP of the client directly
            The true IP of the client is inserted in the header X-Forwarded-For 
            We can also get Port (X-Forwarded-Port) and proto (X-Forwarded-Proto)


4. Network Load Balancer (NLB) v2
    Network load balancers (Layer 4) allow to :
        Forward TCP & UDP traffic to your instances 
        Handle millions of request per seconds 
        Less latency ~ 100 ms (vs 400 ms for ALB)
    NLB has one static IP per AZ, and supports assigning Elastic IP (help ful for whitelisting specific IP)
    NLB are used for extreme performance, TCP or UDP traffic 
    Not included in the AWS free tier 

    Target Groups 
        EC2 instances 
        IP Addresses - must be private IPs 
        ** Application Load Balancer (it is NLB in front of AlB)
        Health CHecks support the TCP, HTTP and HTTPS Protocols 


5. Gateway Load Balancer (GWLB)
    Deploy, scale, and manage a fleet of 3rd party network virtual applicances in AWS 
    Example : Firewalls, Intrusion Detection and Prevention Systems, Deep Packet Inspection System, payload manipulation, ...
    Operates at Layer 3 (Network Layer) - IP Packets 
    Combines the following functions :
        Transparent Network Gateway - single entry/exit for all traffic 
        Load Balancer - distibutes traffic to your virtual appliances 
    ** Uses the GENEVE protocol on port 6081
    User (source) -> GWLB -> Target Group -> GWLB -> Application (destination)

    Target Groups 
        EC2 instances 
        IP Addresses - must be private IPs 


6. Sticky Session (Session Affinity)
    It is possible to implement stickiness so that the same client is always redirected to the same instance behind a load balancer 
    This works for Classic Load Balancers & Application Load Balancers 
    The "cookie" used for stickiness has an expiration date you control 
    Use case: make sure the user doesn't lose his session data 
    Enabling stickiness may bring imbalance to the load over the backend EC2 instances 

    Cookie Names 
        Application-based Cookies 
            Custom cookie 
                Generated by the target 
                Can include any custom attributes required by the application 
                Cookie name must be specified individually for each target group 
                Don't use AWSALB, AWSALBAPP, or AWSALBTG (reserved for use by the ELB)
            Application cookie 
                Generated by the load balancer 
                Cookie name is AWSALBAPP 
        Duration-based Cookies 
            Cookie generated by the load balancer 
            Cookie name is AWSALB for ALB, AWSELB for CLB 

    
7. Cross-Zone Load Balancing
    With Cross Zone Load Balancing :
        each load balancer instance distributes evenly across all registered instances in all AZ 
    Without Cross Zone Load Balacing :
        Requests are distributed in the instances of the node of the Elastic Load Balancer 

    Application Load Balancer 
        Enabled by default (can be disabled at the Target Group level)
        No charges for inter AZ data 
    Network Load Balancer & Gateway Load Balancer 
        Disbled by default
        You pay charges ($) for inter AZ data if enabled


***
8. SSL / TLS - Basics
    An SSL Certificate allows traffic between your clients and your load balancer to be encrypted in transit (in-flight encryption)
    SSL refers to Secure Sockets Layer, used to encrypt connections 
    TLS refers to Transport Layer Security, which is a newer version 
    Nowadays, TLS certificates are mainly used, but people still refer as SSL 
    Public SSL certificates are issued by Certificate Authorities (CA)
    Comodo, Symantec, GoDaddy, GlobalSign, Digicert, Letsencrypt, etc ...
    SSL certificates have an expiration date (you set) and must be renewed

    SSL Certificates 
        The load balancer uses an X.509 certificate (SSL/TLS server certificate)
        You can manage certificates using ACM (AWS Certificate Manager)
        You can create upload your own certificates alternatively
        HTTPS listener :
            You must specify a default certificate 
            You can add an optional list of certs to support multiple domains 
            Clients can use SNI (Server Name Indication) to specify the hostname they reach 
            Ability to specify a security policy to support older versions of SSL / TLS (legacy clients)

    SNI (Sever Name Indication)
        SNI solves the problem of loading multiple SSL certificates onto one web server (to server multiple websites)
        It's a "newer" protocol, and requires the client to indicate the hostname of the target server in the intial SSL handshake
        The server will then find the correct certificate, or return the default one 
        Note :
            Only works for ALB & NLB (newer generation), Cloud Front 
            Does not work for CLB (older gen)

    Classic Load Balancer (v1)
        Support only one SSL certificate 
        Must use multiple CLB for multiple hostname with multiple SSL certificates 
    Application Load Balancer (v2)
        Supports multiple listeners with multiple SSL certificates 
        Uses Server Name Indication (SNI) to make it work 
    Network Load Balancer (v2)
        Supports multiple listeners with multiple SSL certificates 
        Uses Server Name Indication (SNI) to make it work 


9. Connection Draining
    Feature naming
        Connection Draining - for CLB 
        Deregistration Deply - for ALB & NLB 
    Time to complete "in-flight requests" while the instance is de-registering or unhealthy 
    Stops sending new requests to the EC2 instance which is de-registering 
    Between 1 to 3600 seconds (default: 300 seconds)
    Can be disabled (set value to 0)
    Set to a low value if you requests are short 


10. Auto Scaling Group (ASG)
    What's an Auto Scaling Group?
        In real-life, the load on your websites and application can change 
        In the cloud, you can create and get rid of servers very quickly 

        The goal of an Auto Scaling Group (ASG) is to :
            Scale out (add EC2 instances) to match an increased load 
            Scale in (remove EC2 instances) to match a decreased load 
            Ensure we have a minimum and a maximum number of EC2 instances running 
            Automatically register new instances to a load balancer 
            Re-create an EC2 instance in case a previous one is terminated (ex: if unhealthy)
        ASG are free (you only pay for the underlying EC2 instances)

    ELB + ASG 조합은 꽤 좋다.
    ELB는 EC2 instance의 health를 체크하고 unhealthy 상태인 EC2 instance를 ASG에게 전달한다.
    ASG는 unhealthy 상태인 EC2 instance를 제거하고 새로 만든다.

    ASG Attributes 
        A Launch Template (older "Launch Configurations" are deprecated)
            AMI + Instance Type 
            EC2 User Data 
            EBS Volumes 
            Security Groups 
            SSH Key Pair 
            IAM Roles for your EC2 Instances 
            Network + Subnets Information 
            Load Balancer Information 
        Define Min Size / Max Size / Initial Capacity 
        Scaling Policies

    * Cloud Watch Alarms & Scaling 
        It is possible to scale an ASG based on Cloud Watch alarms 
        An alarm monitors a metric (such as Average CPU, or a custom metric)
        Metrics such as Average CPU are computed for the overall ASG instances 
        Based on the alarm :
            We can create scale-out policies (increase the number of instances)
            We can create scale-in policies (decrease the number of instances)

    Policy
        Dynamic Scaling Policies 
            Target Tracking Scaling 
                Most simple and easy to set-up 
                Example: I want the average ASG CPU to stay at around 40%
            Simple / Step Scaling 
                When a CloudWatch alarm is triggered (example CPU > 70%), then add 2 units
                When a CloudWatch alarm is triggered (example CPU < 30%), then remove 1
            Scheduled Actions 
                Anticipate a scaling based on known usage patterns 
                Example: increase the min capacity to 10 at 5 pm on Fridays 
        Predictive Scaling 
            continuously forecast load and schedule scaling ahead  (..by ML??)

    Good metrics to scale on 
        CPUUtilization : Average CPU utilization across your instances 
        RequestCountPerTarget : to make sure the number of requests per EC2 instances is stable 
        Average Network In / Out (if you're application is network bound)
        Any custom metric (that you push using CloudWatch)

    Scaling Cooldowns
        After a scaling activity happens, you are in the cooldown period (default 300 seconds)
        During the cooldown period, the ASG will not launch or terminate additional instances (to allow for metrics to stabilize)
        Advice : Use a ready-to-use AMI to reduce configuration time in order to be serving request fasters and reduce the cooldown period 
        

