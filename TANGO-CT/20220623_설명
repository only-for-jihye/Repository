# 2022.06.23_설명


1. python2 -> python3 Upgrade
    - python2.7.12 -> 3.9.2
        - python2에서 python3로 주된 변경 사항
            - python2에서의 기본 저장 방식은 ASCII로 unicode 방식으로 저장하기 위해서는 별도의 설정이 필요했음
            - python3는 기본 저장 방식이 unicode로 변경됨
              따라서 모든 문자열인 unicode인 str 클래스이기 때문에.. 사용 용도에 따라 bytes -> str 또는 str -> bytes로 변환 필요
            - 최재호 부장님께서 만들어주신 common.utilitys에 to_str, to_bytes 함수 사용, encode() 또는 decode() 함수도 사용
            - Adaptor 기동 Test 시, 형변환 오류가 출력될 시에 위 사항 적용

    - print 구문 변경 - 소스 상에 없음
        - print "Hello" -> print("Hello")

    - 예외처리
        - 기존 - except: 
        - 변경 - except Exception as e :
                 logger.exception(str(e))

    - 내장 함수 변경
        - range() : python2의 xrange()와 python3의 range() 동일하게 변경되어 xrange()가 사라지고 range()만 사용 가능, 적용
        - next : 반복기 (List 형태의 Noti 파일 읽을 때 사용)
            next() -> __next__()
            
    - 그리고... 필요한 py 파일들을 기존 svn repo.에서 ~ooc/~adaptor3 프로젝트에 추가함


2. docker image 만들기
    - docker image로 만들기 위해서 필요한 것들 ..
        1. BMT에서 사용했던 최재호 부장님께서 만들어두신 Docker 파일에 대해 공부하고 변경할 것만 변경했음

        2. /home/tangooc/TANGOOC/adaptor 디렉토리 -> adaptor3로 바꾸고

        3. 최종 변경 시점 기준 (6/21 15시) 소스로 adaptor_pack_2022062115.tar.gz 만듦

        4. python3에 zookeeper 연동을 위한 kazoo 패키지 설치해서 python tar.gz 파일도 만듦
            - adaptor_pack.tar.gz / python.tar.gz 파일을 tg-d5-om-spk1에서 만들어서
            scp로 tg-s-a-emsgs2에 /home/tangosvc/project/TANGO_O_K8S/deploy/version-unmanaged/docker/tango/oc/adaptor로 전송

        5. tango-o-k8s.sh 에 docker image install에서 사용한 구문으로 .. 직접 실행함
            - docker image 만들기 (동일 서버에서 진행)
                docker build --tag tango-o-oc-test:0.1 .
                docker tag tango-o-oc-test:0.1 90.90.227.21:5000/tango-o-oc-test:0.1
                docker push 90.90.227.21:5000/tango-o-oc-test:0.1
                ; * Docker images build 주의점
                ;     - Docker build 시, 파일은 항상 DockerFile이 존재하는 위치에 있어야함
                ;     - 여기서 말하는 파일이란, COPY 또는 ADD에 사용하는 파일이고
                ;     - 컨텍스트 기준으로 DockerFile이 존재하는 곳에서 생성됨
                ;     - ADD는 tar 파일은 압축이 풀려서 추가됨
                ;     - COPY는 tar 파일 압축 안하고 copy만
                # 받고자하는 서버에서 docker 이미지 pull
                # docker pull 90.90.227.21:5000/tango-o-oc-test:0.1
                # yaml 파일의 container의 image에 사용하게 되면, kubectl apply -f에서 imagePullPolicy: "IfNotPresent" 즉, local에 존재하지 않는다면 pull해서 생성함
                # 따라서 직접 서버에서 docker pull 90.90.227.21:5000/tango-o-oc-test:0.1을 사용할 경우는 많이 없음


3. docker image 내에서 python을 돌려보기
    #- docker 참고
    #    1. docker commit
    #        docker container를 image로 생성
    #        commit 명령어를 실행하는 시점의 docker container 상태가 보존
    #        현재 docker container의 상태를 백업하는 경우에 자주 사용
    #    2. docker build
    #        Dockerfile 이라는 단순 텍스트 파일를 사용하여 image 생성
    #        Dockerfile 은 지정된 문법을 지켜야 함
    #        Dockerfile 을 작성하고 공유하면 image의 구성을 쉽게 알 수 있음
    
    - docker image에 /bin/bash로 접속해보기
        docker run -it {docker image id} /bin/bash

    - 직접 돌려보려면 ZOOKEEPER_HOSTS와 POD_NAME을 환경변수로 설정해야함
        export ZOOKEEPER_HOSTS=''
        export POD_NAME=''
        그리고 init-Container 실행 후, adaptor-Container 실행
        cfg 디렉토리에 cfg 파일 추가필요
        # vdi안에 ultra edit에 있음



4. k8s 올리기
    1) master node 접속 (tg-s-a-emsgs1)
    
    2) node 정보 확인
        kubectl get nodes
    
    3) 실행 디렉토리 (임시)
        cd /home/tangosvc/deploy-work/kube-files/tango-o-oc

    4) 순서대로 필요한 yaml 파일 실행
        1. namespace 생성 # 이미 만들어져있음 ns-tgo-oc
            kubectl apply -f oc_name_spaces_js.yaml
        2. configmap 생성
            # configmap은 sh로 만들었음
            ./oc_configmap_js.sh
            # 그냥 의견 .. : 장비별/데이터타입별로 configmap이 달라서 음... 하나로 통합해도 괜찮을 것 같은데 (ex. adaptor-5g-config ?)
            kubectl get configmaps -n ns-tgo-oc
            kubectl describe configmaps -n ns-tgo-oc
            kubectl get configmaps adaptor-5g-ss-ran-pm-config -n ns-tgo-oc -o yaml

        3. service 생성
            StatefulSet은 Service가 필수, headless 서비스 (ClusterIP:None) 만듦
            # 스테이트풀셋은 현재 파드의 네트워크 신원을 책임지고 있는 헤드리스 서비스가 필요하다. 사용자가 이 서비스를 생성할 책임이 있다.
            # ClusterIP, NodePort, LoadBalancer, ExternalName 타입의 서비스는 클라이언트가 Pod에 접근하기 위해
            # kube-proxy로 접근한 후 프록시되어 pod에 액세스 하게 된다. 
            # 프록시로 접근하는 경우, 현재 연결된 Pod와 다음번에 연결될 Pod가 같다는 보장을 할 수 없기 때문에
            # Stateful한 애플리케이션에 적합하지 않다.
            kubectl get service -n ns-tgo-oc

            # zookeeper 서비스 접속할 때, headless 서비스라 ... 
            # headless service는 $(podname).$(servicename).$(namespace).svc.cluster.local:$(port) 을 dns주소로 접속함 
            # headless service는 $(podname).$(servicename):$(port) 을 dns주소로 접속로도 가능, 같은 cluster 내에서

        4. serviceAccount 생성 및 Role 설정
            kubectl apply -f oc_sa_js.yaml
            # serviceAccount 조회
            kubectl get serviceaccount oc-user -n ns-tgo-oc -o yaml
            # 내용을 보면 serviceAccount에는 secret이 할당되어 비밀번호 역할을 한다.
            # secret 보기
            kubectl describe secret oc-user-token-vdlhg -n ns-tgo-oc
            # ClusterRole 설정도 포함
            # Role에는 2가지 방식이 있음
            # ABAC (Attribute-based access control) / RBAC (Role-based access control)
            # 최근에는 RBAC만 사용함, ABAC는 master로 접근해서 사용해야 하나, RBAC는 kubectl이나 API를 이용해서 관리가 편함
            # ClusterRole은 특정 namespace 사용 권한이 아닌, 클러스터 전체 사용 권한을 관리
            kubectl describe clusterrole -n ns-tgo-oc |more
                grep oc-role
        5. StatefulSet pod 실행
            kubectl apply -f tgo-oc-adaptor-5g-ss-ran-pm_js_sts.yaml
            # pod 설정에 spec.podManagementPolicy: Parallel #병렬처리 추가, 순차 기동 문제
            # adminState가 Running이 아니면 기동 X
        
    5) 실행 결과 보기
        kubectl get pods -n ns-tgo-oc
        kubectl describe pods -n ns-tgo-oc |more
    
    6) pod 로그 확인하고 접속해보기
        kubectl -n ns-tgo-oc logs -p oc-adaptor-5g-ss-ran-pm-0

        # * badrequest가 뜰 때,
        # kubectl logs --namespace=ns-tgo-oc -p oc-adaptor-5g-ss-ran-pm-0 --previous=false
        #     * tail도 걸수 있음, 마지막에 -f

        * 동작중인 pod에 들어가서 확인하기
        kubectl exec --stdin --tty oc-adaptor-5g-ss-ran-pm-0 -n ns-tgo-oc -- /bin/bash

    7) 테스트
        테스트 기준, adaptor container는 tg-d5-om-spk1에 데이터를 연동하고 있고
        위 서버의 DummySbiServer에 데이터를 전송하고 있음

        - init-Container가 ADAPTOR_CONFIG_NAME을 잘 떨구는지 보기
        - adaptor-Container가 잘 실행되는지 보기
        - adaptor에서 TailFilePath에 테스트 파일 추가하기
        - DummySbiServer로 전송되는지 보기
        - zookeeper adaptor/config/seed 확인







# 2022.06.20_더해야할 것

# livenessprobe에 추가할 sh 파일 하나 만들기
    - adaptorWatch.py 참고해서 만들어야함
    - true (0)로 떨어지면 OK
    - 그 밖에 X

# 2022.06.23
    - fm adaptor -> fm parser (sts)
    - 동일한 parser에 데이터를 순차적으로 보내게..
    - 하나의 adaptor는 하나의 parser에만 보내게
        fm parser는 partition별로 띄운다 ?
    - cfg 파일 만들 때, 