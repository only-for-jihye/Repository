
Databases 
    We have a lot of managed databases on AWS to choose from 
    Questions to choose the right database based on your architecture :
        Read-heavy, write-heavy, or balanced workload ?
        Throughput needs ? 
        Will it change, does it need to scale or fluctuate during the day ?
        How much data to store and for how long ? 
        Will it grow ?
        Average object size ?
        How are they accessed ?
        Data durability ? 
        Source of truth for the data ?
        ...

Database Types 
    RDBMS (= SQL / OLTP) : RDS, Aurora - great for joins (transaction)
    NoSQL databse - no joins, no SQL : DynamoDB (~JSON), ElastiCache (key / value pairs), Neptune (graphs), DocumentDB (for MongoDB), Keyspaces (for Apache Cassandra)
    Object Store : S3 (for big objects) / Glacier (for backups / archives)
    Data Warehouse (= SQL Analytics / BI) : Redshift (OLAP), Athena, EMR 
    Search : OpenSearch (JSON) - free text, unstructured searches 
    Graphs : Amazon Neptune - displays relationships between data 
    Ledger : Amazon Quantum Ledger Database 
    Time series : Amazon Timestream 

    Note : some databases are being discussed in the Data & Analytics section 


1. Amazon RDS - Summary 
    Managed PostgreSQL / MySQL / Oracle / SQL Server / MariaDB / Custom 
    Provisioned RDS Instance Size and EBS Volume Type & Size 
    Auto-scaling capability for Storage 
    Support for Read Replicas and Multi AZ 
    Security through IAM, Security Groups, KMS, SSL in transit 
    Automated Backup with Point in time restore feature (up to 35 days)
    Manual DB Snapshot for longer-term recovery 
    Managed and Scheduled maintenanace (with downtime)
    Support for IAM Authentication, integration with Secrets Manager 
    RDS Custom for access to and customize the underlying instnace (Oracle & SQL Server)

    Use case : Store relational datasets (RDBMS / OLTP), perform SQL queries, transactions 


2. Amazon Aurora - Summary 
    Compatible API for PostgreSQL / MySQL, separation of storage and compute 
    Storage : data is stored in 6 replicas, across 3 AZ - highly available, self-healing, auto-scaling 
    Compute : Cluster of DB Instance across multiple AZ, auto-scaling of Read Replicas 
    Cluster : Custom endpoints for writer and reader DB instances 
    Same security / monitoring / maintenanace features as RDS 
    Know the backup & restore options for Aurora 
    Aurora Serverless - for unpredictable / intermittent workloads, no capacity planning 
    Aurora Global : up to 16 DB Read Instances in each region, < 1 second storage replication 
    Aurora Machine Learning : perform ML using SageMaker & Comprehend on Aurora 
    Aurora Database Cloning : new cluster from existing one, faster than restoring a snapshot 

    Use case : same as RDS, but with less maintenanace / more flexibility / more performance / more features 


3. Amazon ElastiCache - Summary 
    Managed Redis / Memcached (similar offering as RDS, but for caches)
    In-memory data store, sub-millisecond latency 
    Must provision an EC2 instance type 
    Support for Clustering (Redis) and Multi AZ, Read Replicas (sharding)
    Security through IAM, Security Groups, KMS, Redis Authentication
    Backup / Snapshot / Point in time restore feature
    Managed and Scheduled maintenanace
    "Requires some application code changes to be leveraged"

    Use case : Key/Value store, Frequent reads, less writes, cache result for DB queries, store session data for websites, cannot use SQL 


4. Amazon DynamoDB - Summary 
    AWS proprietary technology, managed serverless NoSQL database, millisecond latency 
    Capacity modes : provisioned capacity with optional auto-scaling or on-demand capacity 
    Can replace ElastiCache as a key/value store (storing session data for example, using TTL feature)
    Highly Available, Multi AZ by default, Read and Writes are decoupled, transaction capability 
    DAX cluster for read cache, microsecond read latency 
    Security, authentication and authorization is done through IAM 
    Event Processing : DynamoDB Streams to integrate with AWS Lambda, or Kinesis Data Streams 
    Global Table feature : active-active setup (양쪽에서 모두 읽기 쓰기 작업 가능)
    Automated backups up to 35 days with PITR (restore to new table), or on-demand backups 
    Export to S3 without using RCU within the PITR window, import from S3 without using WCU 
    "Great to rapidly evolve schemas"

    Use case : Serverless applications development (small documents 100s KB), distributed serverless cache 


